# 应用场景

## 消息

本章主要介绍几种主流的Apache Kafka的应用场景。对这些场景的具体实践的介绍，可以参考[这篇博客](https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying) 。

Kafka作为传统消息中间件的替代者，表现是不错的。有许多原因导致使用消息中间件如解耦数据生产者和消费者，存储未处理的消息等等。与多数消息系统相比，Kafka有更好的吞吐量，内置分区，赋值和容错能力，这使Kafka对大规模消息处理应用来说是一个很好的解决方案。

据我们的经验，消息使用通常吞吐量是相对较低的，但或许需要端对端的低延迟，并十分依赖与Kafka提供的强大的持久性存储保证。

在这方面，Kafka经常拿来与传统消息系统如ActiveMQ或者RabbitMQ相比较。

## 网站活动追踪

Kafka原始的使用场景是能够重新构建一个用户活动追踪管道作为一系列实时发布订阅源。这意味着网站活动\(如页面访问，搜索和用户采取的其他操作\)被发布到每个活动类型都作为一个主题的中心主题。这些数据源在一系列不同的场景中都可以被订阅到，如实时处理，实时监控，拉取数据到Hadoop或者离线数据仓储系统来做离线处理和报表。

活动追踪是非常高频率的以为活动消息是有每个用户的页面访问产生的。

## 指标

Kafka常被用来处理可操作统计的监控数据。这包括从分布式系统收集统计数据并产生可操作的中心化的可操作数据。

## 日志收集

许多人使用Kafka替代日志收集解决方案。日志收集是典型地从服务器采集物理日志文件信息，并将这些信息放在中心化的地方\(可能是文件服务器或者HDFS\)来处理。Kafka抽象了日志文件的细节，并将日志或者数据事件作为消息流非常清晰化的抽象出来。这使得其具有低延迟的处理并且非常容易支持多个数据源，分布式数据消费。相比Scribe或者Flume这些日志中心系统，Kafka提供了同样好的性能，依赖于副本的更强的持久化保证以及端到端的更低的延迟。

## 流处理

很多Kafka用户在由多阶段组成的处理管道中处理数据。其中原始输入数据从Kafka主题中被消费掉，然后收集汇总、丰富或者被传输到新的Kafka主题中做进一步消费或者后续处理。例如一个推荐新闻文章的管道处理可以从RSS爬取文章内容然后发布到主题为"articles"的Kafka集群中，进一步的处理或可能规范化或者复制这些内容然后发布这些清洗过的文章内容到一个新的主题中；最后的处理阶段才尝试将这些内容推荐给用户。这些处理管道创建了基于各个主体的实时数据流图表。从0.10.0.0开始，Apache Kafka提供了轻量级但是功能强大的流处理库，称之为Kafka Streams，可以这行如上所说的数据处理。出Kafka Streams之外，选择开源的流处理工具还包括Apache Storm和Apache Samza。

## 事件溯源

事件溯源\(Event Sourcing\)是一种应用设计风格\(设计模式\)，其将状态变更按照记录的时间序列被记录。Kafka支持存储海量数据使得其成为以改风格构建的应用的出色的后端程序。

## 日志提交

Kafka可以当做一种分布式系统的外部提交日志服务。这些日志有助于在不同节点之间复制数据，并可以作为故障节点恢复其数据的重新同步机制。Kafka日志压缩功能有助于这些用法。这种用法Kafka类似于Apache BookKeeper项目。




# 简介

## Apache Kafka是分布式流平台，什么意思呢？

一个流平台有三个关键能力：

```
1.允许发布和订阅记录流。在这方面kafka类似于消息队列或者企业消息系统。

2.允许一定程度的容错方式存储记录流。

3.允许处理记录流
```

Kafka使用的场景是什么呢？

Kafka适用于两大类应用：

```
1.构建在多个系统或应用之间可靠获取数据的实时数据流管道

2.构建传输或在处理数据流的实时流式应用
```

为了理解Kafka是如何做到这些事情的，需要从下到上分析查看Kafka的能力。

首先如下一些基本概念

```
 1.Kafka集群以类别来存储记录流，这些不同的类别成为主题(topic)

 2.每一条消息由一个关键字key、一个值value和一个时间戳timestamp组成
```

Kafka有四个核心Apis：

```
 1.生产者API允许莺歌应用发布一条记录流到一个或者多个Kafka主题

 2.消费者API允许一个应用订阅一个或者多个主题并且处理为此主题产生的记录流

 3.流API允许一个应用作为一个流处理器，消费来自一个或者多个主题的输入流，产生输出流到一个或者多个主题，高效传输输入流到输出流。

 4.连接器API允许构建和运行可复用的连接Kafka主题到已经存在的应用或者数据系统的生产者或者消费者。例如到关系型数据库的连接系可能
 捕获每一个变化记录到表中。
```

![](/assets/import.png)

在Kafka中，客户端和服务端的连接是基于简单的、高效的、语言无关的TCP协议实现的。该协议是版本记录的并且向后兼容就得版本。官方提供了java客户端，但是其他多种语言的客户端也是可获得的。

## 主题和日志

首先看一下对记录流的核心抽象：主题

主题就是发布的记录的一个分类或者分类名称。在Kafka中主题总是有多个订阅者，也就是说一个主题可以有0个，1个或者多个消费者来订阅写入该主题的数据。

对每一个主题，Kafka集群为录了如下的分区日志：

![](/assets/import1.png)

每个分区都是有序的、不可修改的消息序列，新增的消息被追加到提交日志块中。分区中的每条记录分配一个序列化的数字id称为偏移量\(offerset\)来唯一标记该分区中的每一条消息。

Kafka集群保存所有的发布的记录，不管他们是否已经被消费。保存时间是可配置的。例如，如果保存策略设置为2天，那么2天以内发布的消息都是可获取消费的，而一千的消息将被丢弃来释放空间。Kafka的性能与数据大小无关，所以长时间保存数据是没问题的。

![](/assets/import3.png)

实际上Kafka保存的每一个消费者的元数据仅仅是该消费者在日志中的偏移量或者位置。该偏移量有消费者控制：通常消费者读取消息后其偏移量是线性增加的，但是实际上因为这个位置是由消费者控制的，所以消费者可以以其想用的顺序来消费。例如一个消费者可以可以重置偏移量到之前的位置来重新处理之前的数据或者跳过当最近的记录从现在开始消费。

这些特性一位置Kafka消费者消耗好少的资源：可以添加或者移除消费者而不对集群或者其他消费者太多影响。例如，可以使用命令行工具tail输出任意主题的内容而不改变已有消费者的消费。

日志分区有很多目的：首先，允许日志伸缩超过单台服务器的限制。每个独立的分区受限于他所在的主机服务器，但是一个主题有多个分区所以能够处理随意数量的数据。其次，在并行处理上可以作为一个单元。

## 分布式

分区日志被分发到Kafka集群的机器上。每台机器处理共享分区的数据和请求。每个分区通过可配置的数字来制定赋值的份数以此实现容错性。

每个分区有一台服务器作为领导者\(leader\),零台或多台服务器作为追随者\(followers\)，leader处理这个分区的所有读写请求，而followers则复制leader的数据。如果leader服务器失效，那么followers中的一个会被选举为新的leader。每个服务器都是其某些分区的leader，同时又是其他分区的follower，从而实现了集群的负载均衡。

## 生产者

生产者向其指定主题发布数据。生产者负责将消息发送到指定主题的哪个分区中。可以通过简单的轮询策略来实现负载均衡，也可以通过某些语义实现分区功能\(基于记录中的某些关键字\)。

## 消费者

消费者会通过一个消费者组名称\(consumer group name\)来标记自身。每个主题的每条消息都会分发到所有订阅组中的一个消费者实例。消费者实例可以在不同的程序中也可以在不同的机器上。

![](/assets/import4.png)

由上图可以看出，这是有四个分区的Kafka集群，分区P0-P3，同时有两个订阅组GroupA和GroupB。GroupA有两个订阅者实例\(C1-C2\)，GroupB有四个实例\(C3-C6\)。

通常，我们发现每个主题一般会有少量的订阅组，每个订阅组都可以看成一个逻辑上的消费者\(如上文所说消息只会发送到该订阅组的一个订阅者实例上而不是所有的订阅者实例\)。每个订阅组包含多个消费者实例来实现扩容和容错性。这也是发布-订阅模式只不过订阅者是一个消费集群而不是一个单独的程序。

Kafka中分区的实现方式是将日志中的分区划分到消费者实例上，以便每个实例在任何时间点都是共享分区唯一的消费者。维护订阅组中成员关系是通过Kafka协议动态处理的。如果新的实例加入到群组中，那么新的实例就从群组中其他成员接管某些分区；如果一个势力失效，该实例负责的分区就会分发给该群组中剩余的实例。

Kafka只提供主题中一个分区内记录的全局有序，而不提供主体中不同分区间记录的全局有效性。分区内记录的全局有序性和根据某些关键字分区的能力对大多数应用来说已经足够。如果需要主题内分区间消息的全局有序性，可以将一个主题只有一个分区，这也就意味着每个消费者群组只有一个消费者程序。

## 保证

Kafka的高级功能提供如下保证：

生产者发送消息到指定的主题分区是按照消息发送的顺序追加的。也就是说，同一个生产者发送了两个记录M1和M2，并且先发送M1，再发送M2，那么M1在日志中有更小的偏移量\(offset\)并且更早的进入日志数据中。


































# 简介

## Apache Kafka是分布式流平台，什么意思呢？

一个流平台有三个关键能力：

```
1.允许发布和订阅记录流。在这方面kafka类似于消息队列或者企业消息系统。

2.允许一定程度的容错方式存储记录流。

3.允许处理记录流
```

Kafka使用的场景是什么呢？

Kafka适用于两大类应用：

```
1.构建在多个系统或应用之间可靠获取数据的实时数据流管道

2.构建传输或在处理数据流的实时流式应用
```

为了理解Kafka是如何做到这些事情的，需要从下到上分析查看Kafka的能力。

首先如下一些基本概念

```
 1.Kafka集群以类别来存储记录流，这些不同的类别成为主题(topic)

 2.每一条消息由一个关键字key、一个值value和一个时间戳timestamp组成
```

Kafka有四个核心Apis：

```
 1.生产者API允许莺歌应用发布一条记录流到一个或者多个Kafka主题

 2.消费者API允许一个应用订阅一个或者多个主题并且处理为此主题产生的记录流

 3.流API允许一个应用作为一个流处理器，消费来自一个或者多个主题的输入流，产生输出流到一个或者多个主题，高效传输输入流到输出流。

 4.连接器API允许构建和运行可复用的连接Kafka主题到已经存在的应用或者数据系统的生产者或者消费者。例如到关系型数据库的连接系可能
 捕获每一个变化记录到表中。
```

![](/assets/import.png)

在Kafka中，客户端和服务端的连接是基于简单的、高效的、语言无关的TCP协议实现的。该协议是版本记录的并且向后兼容就得版本。官方提供了java客户端，但是其他多种语言的客户端也是可获得的。

## 主题和日志

首先看一下对记录流的核心抽象：主题

主题就是发布的记录的一个分类或者分类名称。在Kafka中主题总是有多个订阅者，也就是说一个主题可以有0个，1个或者多个消费者来订阅写入该主题的数据。

对每一个主题，Kafka集群为录了如下的分区日志：

![](/assets/import1.png)

每个分区都是有序的、不可修改的消息序列，新增的消息被追加到提交日志块中。分区中的每条记录分配一个序列化的数字id称为偏移量\(offerset\)来唯一标记该分区中的每一条消息。

Kafka集群保存所有的发布的记录，不管他们是否已经被消费。保存时间是可配置的。例如，如果保存策略设置为2天，那么2天以内发布的消息都是可获取消费的，而一千的消息将被丢弃来释放空间。Kafka的性能与数据大小无关，所以长时间保存数据是没问题的。

![](/assets/import3.png)

实际上Kafka保存的每一个消费者的元数据仅仅是该消费者在日志中的偏移量或者位置。该偏移量有消费者控制：通常消费者读取消息后其偏移量是线性增加的，但是实际上因为这个位置是由消费者控制的，所以消费者可以以其想用的顺序来消费。例如一个消费者可以可以重置偏移量到之前的位置来重新处理之前的数据或者跳过当最近的记录从现在开始消费。

这些特性一位置Kafka消费者消耗好少的资源：可以添加或者移除消费者而不对集群或者其他消费者太多影响。例如，可以使用命令行工具tail输出任意主题的内容而不改变已有消费者的消费。

日志分区有很多目的：首先，允许日志伸缩超过单台服务器的限制。每个独立的分区受限于他所在的主机服务器，但是一个主题有多个分区所以能够处理随意数量的数据。其次，在并行处理上可以作为一个单元。

## 分布式

分区日志被分发到Kafka集群的机器上。每台机器处理共享分区的数据和请求。每个分区通过可配置的数字来制定赋值的份数以此实现容错性。

每个分区有一台服务器作为领导者\(leader\),零台或多台服务器作为追随者\(followers\)，leader处理这个分区的所有读写请求，而followers则复制leader的数据。如果leader服务器失效，那么followers中的一个会被选举为新的leader。每个服务器都是其某些分区的leader，同时又是其他分区的follower，从而实现了集群的负载均衡。

## 生产者

生产者向其指定主题发布数据。生产者负责将消息发送到指定主题的哪个分区中。可以通过简单的轮询策略来实现负载均衡，也可以通过某些语义实现分区功能\(基于记录中的某些关键字\)。

## 消费者

消费者会通过一个消费者组名称\(consumer group name\)来标记自身。每个主题的每条消息都会分发到所有订阅组中的一个消费者实例。消费者实例可以在不同的程序中也可以在不同的机器上。

![](/assets/import4.png)

由上图可以看出，这是有四个分区的Kafka集群，分区P0-P3，同时有两个订阅组GroupA和GroupB。GroupA有两个订阅者实例\(C1-C2\)，GroupB有四个实例\(C3-C6\)。

通常，我们发现每个主题一般会有少量的订阅组，每个订阅组都可以看成一个逻辑上的消费者\(如上文所说消息只会发送到该订阅组的一个订阅者实例上而不是所有的订阅者实例\)。每个订阅组包含多个消费者实例来实现扩容和容错性。这也是发布-订阅模式只不过订阅者是一个消费集群而不是一个单独的程序。

Kafka中分区的实现方式是将日志中的分区划分到消费者实例上，以便每个实例在任何时间点都是共享分区唯一的消费者。维护订阅组中成员关系是通过Kafka协议动态处理的。如果新的实例加入到群组中，那么新的实例就从群组中其他成员接管某些分区；如果一个势力失效，该实例负责的分区就会分发给该群组中剩余的实例。

Kafka只提供主题中一个分区内记录的全局有序，而不提供主体中不同分区间记录的全局有效性。分区内记录的全局有序性和根据某些关键字分区的能力对大多数应用来说已经足够。如果需要主题内分区间消息的全局有序性，可以将一个主题只有一个分区，这也就意味着每个消费者群组只有一个消费者程序。

## 保证

Kafka的高级功能提供如下保证：

生产者发送消息到指定的主题分区是按照消息发送的顺序追加的。也就是说，同一个生产者发送了两个记录M1和M2，并且先发送M1，再发送M2，那么M1在日志中有更小的偏移量\(offset\)并且更早的进入日志数据中。

一个消费者实例是按日志中记录的存储顺序获取记录的。

对于有N个副本的主题，Kafka最多容忍N-1个服务器故障并且保证不丢失提交到日志的任何记录。

## Kafka作为消息系统

Kafka中流的概念和传统企业级消息系统相比又如何呢？

传统消息有两种模式：队列模式和发布-订阅模式。在队列模式中，消费者池中所有的消费者都从指定服务器上读取消息记录，每一条记录都会被其中一个消费者读取。在发布订阅模式中，记录是被广播给所有的消费者。这两种模式各有优劣，队列模式的优点是允许对数据的处理划分给多个消费者实例，这可以横向扩展处理程序。但缺点是队列模式不允许多个订阅者，一旦一个处理程序读取了数据，该数据就被删掉了。发布订阅模式允许广播数据给多个处理程序，但是因为每条消息都要发给每个订阅者，所以没办法横向扩展处理程序。

Kafka中消费者群组的概念包括了这两个概念。作为队列的时候允许划分处理程序给一个处理集合\(消费者群组的成员\)。而作为发布-订阅模式的时候，Kafka允许广播消息给多个消费者群组。

Kafka模式的优点是每个主题\(topic\)都拥有如上两个特性。即能够横向扩展处理程序也能够是多订阅者，而不是只能二选一。

Kafka比传统消息系统有更严格的保证消息顺序的机制。

传统的队列在服务器上按顺序存储记录，如果多个消费者从队列中消费消息，那么服务器按照消息的存储顺序向外发送。然而，即使服务器按顺序向外发送记录，那该条消息就会异步分发给消费者，所以这些消息未必按顺序到大不同的消费者。这种高效的方式意味着并行消费代替了记录顺序。消息系统通过“排他消费者”的概念来避免此种情况。也就是说一个队列只允许一个消费者，这当然也就是不能并行处理。

Kafka在这方面做的无疑是更好的。通过一个叫做“主题内分区并行”的概念，Kafka能够保证顺序和消费者池中消费者的负载均衡。是通过分配主题内不同分区给消费者群组中的消费者实现的。这样每个分区只有被消费者群组内唯一的一个消费者消费。通过这样做，我们确保一个消费者是这个分区的唯一消费者，并且按顺序消费数据。因为有多个分区所以可以对多个消费者实例进行负载均衡。注意：无论如何消费者群组中的消费者实例数量不能多于分区数量。

## Kafka作为存储系统

任何消息队列对正在传输的消息作为一个存储系统是十分有效的，该队列允许发布消息并解耦消费这些消息。Kafka的不同在于本身是一个非常好的存储系统。

写入到Kafka的数据是被写入磁盘并复制进行容错处理。Kafka允许生产者等待确认所以在被完全复制前是不认为完成的，并且即使服务器失败也保证持久化数据。

Kafka使用的磁盘结构能够很好的扩展。在服务器上不论你存储50KB还是50TB的数据，Kafka的性能是一样的。

严格存储和允许客户端控制他们读取的位置的结果就是可以把Kafka当做一种具有特殊作用的专用于高性能、日志提交存储低延时，复制和传播的分布式文件系统。

## Kafka的流处理

仅仅读取、写入和保存数据流是不够的，Kafka目的是实现对数据流的实时处理。

在Kafka中，一个流处理器是从输入主题持续地接受任何数据，并对这些输入进行一些处理，然后持续的向输出主题产生数据流。

例如，一个零售应用从销售和货物作为输入流，并对这些数据进行计算产生一个重新排序和价格调整的输出流。

可以直接使用生产者和消费者API来作为某些简单的处理，但是对于复杂的传输，Kafka提供了一套完整的集成的流API。`允许构建的应用做一些有价值的处理，即整合或者连接流进行计算。`

这种能力帮助解决了该种类型的应用面临的复杂问题：如处理无须数据，由于代码修改而对输入重新处理，执行有状态计算等等。

流API基于Kafka提供的核心语义进行构建：使用生产者和消费者的API进行输入，使用Kafka进行有状态存储，并在流处理器实例之间用相同的群组机制来实现容错。





